{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#calibration consists in 3 steps:\n",
    "# 1. find corners in a dataset of images \n",
    "# 2. Use corner points to compute a camera matrix\n",
    "# 3. Use the camera matrix to undistort images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct database\n"
     ]
    }
   ],
   "source": [
    "# read images and convert them to gray\n",
    "\n",
    "#Load images from stereo_calibration_images and separate the ones taken from right camera and left camera\n",
    "\n",
    "imgs_right = glob.glob('calibration_img/left/*.png')\n",
    "imgs_left=glob.glob('calibration_img/right/*.png')\n",
    "assert imgs_right\n",
    "assert imgs_left\n",
    "\n",
    "if (len(imgs_left)==len(imgs_right)):\n",
    "    print(\"Correct database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. FIND CORNERS\n",
    "\n",
    "nb_vertical= 9\n",
    "nb_horizontal= 6\n",
    "chessboardSize= (9,6)\n",
    "\n",
    "frameSize= (1280,720)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((nb_horizontal*nb_vertical,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nb_vertical,0:nb_horizontal].T.reshape(-1,2)\n",
    "\n",
    "#objp = objp*33.6 #multiplying with the actual size of the checker board square MIGHT NEED IT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays to store object points and image points from all the images.\n",
    "objpointsL = [] # 3d point in real world space left\n",
    "objpointsR = [] # 3d point in real world space right\n",
    "imgpointsL = [] # 2d points in image plane left\n",
    "imgpointsR = [] # 2d points in image plane right\n",
    "\n",
    "# define a criteria for the termination of iteration for looking for corners\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "for imgLeft, imgRight in zip(imgs_left, imgs_right):\n",
    "\n",
    "    imgL = cv2.imread(imgLeft)\n",
    "    imgR = cv2.imread(imgRight)\n",
    "    grayL = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)\n",
    "    grayR = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners for all images\n",
    "    retL, cornersL = cv2.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv2.findChessboardCorners(grayR, chessboardSize, None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if retL and retR == True:\n",
    "\n",
    "        objpointsL.append(objp)\n",
    "        cornersL = cv2.cornerSubPix(grayL, cornersL, (11,11), (-1,-1),criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "\n",
    "        objpointsR.append(objp)\n",
    "        cornersR = cv2.cornerSubPix(grayR, cornersR, (11,11), (-1,-1), criteria)\n",
    "        imgpointsR.append(cornersR)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        #this can be commented out if we dont want to see the images (faster)\n",
    "        \n",
    "        cv2.drawChessboardCorners(imgL, chessboardSize, cornersL, retL)\n",
    "        cv2.imshow('img left', imgL)\n",
    "        cv2.drawChessboardCorners(imgR, chessboardSize, cornersR, retR)\n",
    "        cv2.imshow('img right', imgR)\n",
    "        cv2.waitKey(10000)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[699.99033698   0.         647.56623587]\n",
      " [  0.         700.19344877 372.87689895]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 2. USE CORNER POINTS TO COMPUTE CAMERA MATRIX (CALIBRATION)\n",
    "\n",
    "#Using the extracted corners we can obtain a camera matrix that contains the information needed to undistort images\n",
    "\n",
    "#(success, cameramatrix, distorsion parameters, rotation vectors, translation vector)\n",
    "retL, cameraMatrixL, distL, rvecsL, tvecsL = cv2.calibrateCamera(objpointsL, imgpointsL, frameSize, None, None) #none as default\n",
    "heightL, widthL = imgL.shape[:2] #used to generate a new camera matrix (optimal)\n",
    "newCameraMatrixL, roi_L = cv2.getOptimalNewCameraMatrix(cameraMatrixL, distL, (widthL, heightL), 1, (widthL, heightL))\n",
    "\n",
    "retR, cameraMatrixR, distR, rvecsR, tvecsR = cv2.calibrateCamera(objpointsR, imgpointsR, frameSize, None, None)\n",
    "heightR, widthR = imgR.shape[:2]\n",
    "newCameraMatrixR, roi_R = cv2.getOptimalNewCameraMatrix(cameraMatrixR, distR, (widthR, heightR), 1, (widthR, heightR))\n",
    "\n",
    "\n",
    "print(cameraMatrixL) #we will need it for the kalman implementation\n",
    "\n",
    "#most important parameters are the camera matrix and distortion parameters to do the calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stereo Vision Calibration\n",
    "\n",
    "flags = cv2.CALIB_RATIONAL_MODEL # flag needed for the stereoCalibrate function\n",
    "\n",
    "# This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix\n",
    "retStereo, newCameraMatrixL, distL, newCameraMatrixR, distR, rot, trans, essentialMatrix, fundamentalMatrix = cv2.stereoCalibrate(objpointsL, imgpointsL, imgpointsR, newCameraMatrixL, distL, newCameraMatrixR, distR, frameSize, None, None, None, None, flags) #how we relate one camera to the other\n",
    "#return values from stereocalibration- 2 new camera matrixes, distortion parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. USE CAMERA MATRIX TO UNDISTORT IMAGES (Stereo Rectification)\n",
    "\n",
    "\n",
    "# sereorectify: computes and saves rectification of matrix of the 2 cameras (from stereocalibration)\n",
    "rectL, rectR, projMatrixL, projMatrixR, Q, roi_L, roi_R= cv2.stereoRectify(newCameraMatrixL, distL, newCameraMatrixR, distR, frameSize, rot, trans, None, None, None, None) #using default parameters \n",
    "\n",
    "stereoMapL = cv2.initUndistortRectifyMap(newCameraMatrixL, distL, rectL, projMatrixL, frameSize, cv2.CV_32FC1)\n",
    "stereoMapR = cv2.initUndistortRectifyMap(newCameraMatrixR, distR, rectR, projMatrixR, frameSize, cv2.CV_32FC1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. SAVING CAMERA PARAMETERS\n",
    "\n",
    "cv_file = cv2.FileStorage('stereoMap.xml', cv2.FILE_STORAGE_WRITE)\n",
    "\n",
    "cv_file.write('stereoMapL_x',stereoMapL[0])\n",
    "cv_file.write('stereoMapL_y',stereoMapL[1])\n",
    "\n",
    "cv_file.write('stereoMapR_x',stereoMapR[0])\n",
    "cv_file.write('stereoMapR_y',stereoMapR[1])\n",
    "\n",
    "cv_file.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct database\n",
      "1567\n"
     ]
    }
   ],
   "source": [
    "# STEREORECTIFICATION OF NOT OCLUDED INPUT VIDEO\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#Load images\n",
    "notoccluded_left = glob.glob('../video/not_occluded/left/*.png')\n",
    "notoccluded_right = glob.glob('../video/not_occluded/right/*.png')\n",
    "\n",
    "#assert notocluded_left, notocluded_right\n",
    "\n",
    "if (len(notoccluded_right)==len(notoccluded_left)):\n",
    "    print(\"Correct database\")\n",
    "\n",
    "num_imgs= len(notoccluded_left)\n",
    "\n",
    "for i in range(0,num_imgs):\n",
    "\n",
    "\t#takes each frame one by one and rectifies using right stereomap\n",
    "\tframe_left = cv2.imread(notoccluded_left[i])\n",
    "\tleft_good= cv2.remap(frame_left, stereoMapL[0], stereoMapL[1], cv2.INTER_LINEAR)\n",
    "\tcv2.imwrite('videos_rectified/not_occluded/left/leftimage'+str(i)+'.png', left_good)\n",
    "\n",
    "\tframe_right= cv2.imread(notoccluded_right[i])\n",
    "\tright_good= cv2.remap(frame_right, stereoMapR[0], stereoMapR[1], cv2.INTER_LINEAR)\n",
    "\tcv2.imwrite('videos_rectified/not_occluded/right/rightimage'+str(i)+'.png', right_good)\n",
    "\n",
    "#Now we can use the input images from either the left or right calibrated camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct database\n"
     ]
    }
   ],
   "source": [
    "# STEREORECTIFICATION OF OCLUDED INPUT VIDEO\n",
    "\n",
    "#Load images\n",
    "\n",
    "occluded_left = glob.glob('../video/occluded/left/*.png')\n",
    "occluded_right = glob.glob('../video/occluded/right/*.png')\n",
    "\n",
    "if (len(occluded_right)==len(occluded_left)):\n",
    "    print(\"Correct database\")\n",
    "\n",
    "num_imgs= len(occluded_left)\n",
    "\n",
    "for i in range(0,num_imgs):\n",
    "\n",
    "\t#takes each frame one by one and rectifies using right stereomap\n",
    "\tframe_left = cv2.imread(occluded_left[i])\n",
    "\tleft_good= cv2.remap(frame_left, stereoMapL[0], stereoMapL[1], cv2.INTER_LINEAR)\n",
    "\tcv2.imwrite('videos_rectified/occluded/left/leftimage'+str(i)+'.png', left_good)\n",
    "\n",
    "\tframe_right= cv2.imread(notoccluded_right[i])\n",
    "\tright_good= cv2.remap(frame_right, stereoMapR[0], stereoMapR[1], cv2.INTER_LINEAR)\n",
    "\tcv2.imwrite('videos_rectified/occluded/right/rightimage'+str(i)+'.png', right_good)\n",
    "\n",
    "\n",
    "#Now we can use the input images from either the left or right calibrated camera"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e81a7d408b84629da7280e4b5e5c6ea4c6dfe1c48d5b31641e461ecf54ae697"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
