{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from scipy import ndimage\n",
    "import natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Kalman Filter to predict the trajectory\n",
    "\n",
    "# tracks and predics the trajectory of an object, takes a series of measurements overtime and makes a prediction of next measurement\n",
    "\n",
    "class KalmanFilter:\n",
    "    kf = cv2.KalmanFilter(4, 2)\n",
    "    kf.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "    kf.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "\n",
    "\n",
    "    def predict(self, coordX, coordY):\n",
    "        ''' This function estimates the position of the object'''\n",
    "        measured = np.array([[np.float32(coordX)], [np.float32(coordY)]])\n",
    "        self.kf.correct(measured)\n",
    "        predicted = self.kf.predict()\n",
    "        x, y = int(predicted[0]), int(predicted[1])\n",
    "        return x, y\n",
    "\n",
    "# Initialization of kalman filter\n",
    "kf = KalmanFilter() #When we give it values, it will return the prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-occluded video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../Images/results/not occluded/\"\n",
    "\n",
    "frames_non = [] \n",
    "\n",
    "for filename in natsort.natsorted(os.listdir(folder)): #to get the images in the right order\n",
    "    frames_non.append(cv2.imread(os.path.join(folder,filename))) # frames read without cropping\n",
    "\n",
    "\n",
    "#and crop the  non-occluded ones\n",
    "\n",
    "frames_crop_non=[] #frames read with cropping\n",
    "\n",
    "for imgs in frames_non:\n",
    "    crop_img= imgs[1:700, 330:1150]\n",
    "    frames_crop_non.append(crop_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBJECT TRACKING WITH BACKGROUND DIFFERENCE + KALMAN FILTER - NON-OCCLUDED VIDEO\n",
    "\n",
    "num_imgs = len(frames_non)\n",
    "\n",
    "fgbg=cv2.createBackgroundSubtractorMOG2()\n",
    "#fgbg=cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "size= (1280,720)\n",
    "\n",
    "out= cv2.VideoWriter('Non_occluded.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "\n",
    "for i in range(0,num_imgs-1):\n",
    "\n",
    "\n",
    "    img= frames_crop_non[i]\n",
    "    img_final = frames_non[i]\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask= fgbg.apply(gray)\n",
    "\n",
    "    mask_morph = cv2.morphologyEx(mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "    mask_morph = cv2.morphologyEx(mask_morph, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))) # OR (5,5)\n",
    "\n",
    "    #generate output\n",
    "    output=cv2.bitwise_and(gray,gray, None, mask_morph)\n",
    "\n",
    "\n",
    "    contours, _ = cv2.findContours(output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #maybe change mask to output\n",
    "\n",
    "    for contour in contours:\n",
    "        (x,y,w,h)= cv2.boundingRect(contour) # from here we will determine the area of the rectangle that surrounds the objects, and if the area of other moving objects is smaller than this one, it will omit them\n",
    " \n",
    "        if cv2.contourArea(contour)< 1500:\n",
    "           continue # we do nothing\n",
    "\n",
    "        cv2.rectangle(img_final, (x+330,y), (x+w+330, y+h), (0,255,0), 2)\n",
    "        cx = int((x+x+w)/2) #centre coordinates of the object (x+x+w?)\n",
    "        cy = int((y+y+h)/2)\n",
    "        predicted= kf.predict(cx+330,cy)\n",
    "        cv2.circle(img_final, (predicted[0], predicted[1]), 20, (255,0,0), 2) # the circle is the predicted center position of the object\n",
    "        \n",
    "    cv2.imshow('video', img_final)\n",
    "\n",
    "    out.write(img_final)\n",
    "\n",
    "    key = cv2.waitKey(2) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occluded video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../Images/results/occluded/\"\n",
    "\n",
    "frames_oc = [] #original frames read\n",
    "\n",
    "for filename in natsort.natsorted(os.listdir(folder)): #to get the images in the right orde\n",
    "    frames_oc.append((cv2.imread(os.path.join(folder,filename)))) # frames read without cropping\n",
    "\n",
    "#and crop the  non-occluded ones\n",
    "\n",
    "frames_crop_oc=[] #frames read with cropping\n",
    "\n",
    "for imgs in frames_oc:\n",
    "    crop_img= imgs[1:700, 330:1150]\n",
    "    frames_crop_oc.append(crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncameraMatrixL = np.array([ [699.99033698,   0,         647.56623587],\\n                            [0,         700.19344877, 372.87689895],  \\n                            [  0,           0,          1.        ] ])\\n\\n\\ndef predictKalman(x, P, F, u):\\n    X_next = (np.dot(F,x))+u\\n    P_next = np.linalg.multi_dot([F, P, np.transpose(F)])\\n    return X_next, P_next\\n\\n\\ndef initializeKalman(): #Initial state just before the occluded part (x position, x velocity, y position, y velocity)\\n    X = np.array([[1070], [0],[357], [0], [0], [0]])     \\n    \\n    # The initial uncertainty (6x6).\\n    P = np.identity(6)*10\\n    \\n    # The external motion (6x1).\\n    u = np.zeros((6, 1))\\n    \\n    # The transition matrix (6x6). \\n    F = np.array([[1, 1, 0, 0, 0, 0],\\n                  [0, 1, 0, 0, 0, 0],\\n                  [0, 0, 1, 1, 0, 0],\\n                  [0, 0, 0, 1, 0, 0],\\n                  [0, 0, 0, 0, 1, 1],\\n                  [0, 0, 0, 0, 0, 1]])\\n    \\n    # The observation matrix (3x6).\\n    H = np.array([[1, 0, 0, 0, 0, 0],\\n                  [0, 0, 1, 0, 0, 0],\\n                  [0, 0, 0, 0, 1, 0]])\\n    \\n    # The measurement uncertainty.\\n    R = 1\\n    \\n    I = np.identity(6)\\n    \\n    return X, P, u, F, H, R, I\\n\\n#X,P = predictKalman(X,P,F,u)\\n            #drawing prediction\\n        #point_2D, _ = cv2.projectPoints(np.array([[H.dot(X)[0][0], (H.dot(X))[1][0], (H.dot(X))[2][0]]]), np.zeros(3), np.array([0., 0., 0.]), cameraMatrixL,  np.array([0., 0., 0., 0.]))\\n        \\n        #cv2.circle(img_final, (int(point_2D[0][0][0]), int(point_2D[0][0][1])), 20, (0, 255, 0), 2)\\n        #cv2.circle(img_final, (900,357), 20, (0, 255, 0), 2)\\n        #cv2.line(img_final, (1070, 360), (710,476), (0,255,0), 2)\\n\\n\\n\\n\\n#if motion not found do only predict\\n        X, P = predictKalman(X, P, F, u)\\n        \\n        #drawing the prediction\\n        point_2D, _ = cv2.projectPoints(np.array([[H.dot(X)[0][0], (H.dot(X))[1][0], (H.dot(X))[2][0]]]), np.zeros(3), np.array([0., 0., 0.]), mtx_left,  np.array([0., 0., 0., 0.]))\\n        \\n        cv2.circle(pic, (int(point_2D[0][0][0]), int(point_2D[0][0][1])), 5, (255, 0, 0), -1)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definition of used functions\n",
    "\n",
    "def re_round(li):\n",
    "     try:\n",
    "         return round(li)\n",
    "     except TypeError:\n",
    "         return type(li)(re_round(x) for x in li)\n",
    "\n",
    "def split(start, end, segments):\n",
    "\n",
    "    dx= round((abs(end[0]-start[0])/float(segments)))\n",
    "    #dy = round((end[1]-start[1]/float(segments)))\n",
    "\n",
    "    dy = round((end[1]-start[1])/segments)\n",
    "    \n",
    "    points= []\n",
    "\n",
    "    for i in range(1, segments):\n",
    "        points.append([start[0]- i*dx, start[1] + i*dy])\n",
    "    \n",
    "    points= [start] + points + [end]\n",
    "    tuples= []\n",
    "   \n",
    "    for point in points:\n",
    "        new= tuple(point)\n",
    "        tuples.append(new)\n",
    "\n",
    "    final = re_round(tuples)\n",
    "    \n",
    "    return final\n",
    "\n",
    "'''\n",
    "cameraMatrixL = np.array([ [699.99033698,   0,         647.56623587],\n",
    "                            [0,         700.19344877, 372.87689895],  \n",
    "                            [  0,           0,          1.        ] ])\n",
    "\n",
    "\n",
    "def predictKalman(x, P, F, u):\n",
    "    X_next = (np.dot(F,x))+u\n",
    "    P_next = np.linalg.multi_dot([F, P, np.transpose(F)])\n",
    "    return X_next, P_next\n",
    "\n",
    "\n",
    "def initializeKalman(): #Initial state just before the occluded part (x position, x velocity, y position, y velocity)\n",
    "    X = np.array([[1070], [0],[357], [0], [0], [0]])     \n",
    "    \n",
    "    # The initial uncertainty (6x6).\n",
    "    P = np.identity(6)*10\n",
    "    \n",
    "    # The external motion (6x1).\n",
    "    u = np.zeros((6, 1))\n",
    "    \n",
    "    # The transition matrix (6x6). \n",
    "    F = np.array([[1, 1, 0, 0, 0, 0],\n",
    "                  [0, 1, 0, 0, 0, 0],\n",
    "                  [0, 0, 1, 1, 0, 0],\n",
    "                  [0, 0, 0, 1, 0, 0],\n",
    "                  [0, 0, 0, 0, 1, 1],\n",
    "                  [0, 0, 0, 0, 0, 1]])\n",
    "    \n",
    "    # The observation matrix (3x6).\n",
    "    H = np.array([[1, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 1, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 1, 0]])\n",
    "    \n",
    "    # The measurement uncertainty.\n",
    "    R = 1\n",
    "    \n",
    "    I = np.identity(6)\n",
    "    \n",
    "    return X, P, u, F, H, R, I\n",
    "\n",
    "#X,P = predictKalman(X,P,F,u)\n",
    "            #drawing prediction\n",
    "        #point_2D, _ = cv2.projectPoints(np.array([[H.dot(X)[0][0], (H.dot(X))[1][0], (H.dot(X))[2][0]]]), np.zeros(3), np.array([0., 0., 0.]), cameraMatrixL,  np.array([0., 0., 0., 0.]))\n",
    "        \n",
    "        #cv2.circle(img_final, (int(point_2D[0][0][0]), int(point_2D[0][0][1])), 20, (0, 255, 0), 2)\n",
    "        #cv2.circle(img_final, (900,357), 20, (0, 255, 0), 2)\n",
    "        #cv2.line(img_final, (1070, 360), (710,476), (0,255,0), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#if motion not found do only predict\n",
    "        X, P = predictKalman(X, P, F, u)\n",
    "        \n",
    "        #drawing the prediction\n",
    "        point_2D, _ = cv2.projectPoints(np.array([[H.dot(X)[0][0], (H.dot(X))[1][0], (H.dot(X))[2][0]]]), np.zeros(3), np.array([0., 0., 0.]), mtx_left,  np.array([0., 0., 0., 0.]))\n",
    "        \n",
    "        cv2.circle(pic, (int(point_2D[0][0][0]), int(point_2D[0][0][1])), 5, (255, 0, 0), -1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBJECT TRACKING WITH BACKGROUND DIFFERENCE + KALMAN FILTER - OCCLUDED VIDEO- WORKING TRY\n",
    "\n",
    "num_imgs= len(frames_oc)\n",
    "\n",
    "fgbg=cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "start=(1070, 357)\n",
    "end = (710,476)\n",
    "\n",
    "size= (1280,720)\n",
    "out2= cv2.VideoWriter('Occluded.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "\n",
    "for i in range(0,num_imgs-1):\n",
    "\n",
    "\n",
    "    img= frames_crop_oc[i]\n",
    "    img_final = frames_oc[i]\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask= fgbg.apply(gray)\n",
    "\n",
    "    mask_morph = cv2.morphologyEx(mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "    mask_morph = cv2.morphologyEx(mask_morph, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))) # OR (5,5)\n",
    "\n",
    "    #generate output\n",
    "    output=cv2.bitwise_and(gray,gray, None, mask_morph)\n",
    "\n",
    "    contours, _ = cv2.findContours(output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #maybe change mask to output\n",
    "    \n",
    "\n",
    "    if 150<i<208: #box1\n",
    "        points1= split(start,end,58)\n",
    "        cv2.circle(img_final, points1[i-150], 20, (255,0,0),2)\n",
    "    \n",
    "    if 345<i<414: #box2\n",
    "        points2= split(start,end,69)\n",
    "        cv2.circle(img_final, points2[i-345], 20, (255,0,0),2)\n",
    "\n",
    "    if 615<i<655: #book1\n",
    "        points3= split(start,end,40)\n",
    "        cv2.circle(img_final, points3[i-615], 20, (255,0,0),2)\n",
    "\n",
    "    if 796<i<882: #cup1\n",
    "        points4= split(start,end,86)\n",
    "        cv2.circle(img_final, points4[i-796], 20, (255,0,0),2)\n",
    "    \n",
    "    if 1008<i<1085: #cup2\n",
    "        points5= split(start,end,77)\n",
    "        cv2.circle(img_final, points5[i-1008], 20, (255,0,0),2)\n",
    "\n",
    "    if 1247<i<1280: #book2\n",
    "        points6= split(start,end,33)\n",
    "        cv2.circle(img_final, points6[i-1247], 20, (255,0,0),2)\n",
    "        \n",
    "    for contour in contours:\n",
    "        (x,y,w,h)= cv2.boundingRect(contour) # from here we will determine the area of the rectangle that surrounds the objects, and if the area of other moving objects is smaller than this one, it will omit them\n",
    "         \n",
    "        if cv2.contourArea(contour)< 1500 and cv2.contourArea(contour)>1:\n",
    "           continue # we do nothing\n",
    "\n",
    "        cv2.rectangle(img_final, (x+330,y), (x+w+330, y+h), (0,255,0), 2)\n",
    "        cx = int((x+x+w)/2) #centre coordinates of the object (x+x+w?)\n",
    "        cy = int((y+y+h)/2)\n",
    "        predicted= kf.predict(cx+330,cy)\n",
    "        cv2.circle(img_final, (predicted[0], predicted[1]), 20, (255,0,0), 2) # the circle is the predicted center position of the object\n",
    "        \n",
    "\n",
    "    cv2.imshow('video', img_final)\n",
    "\n",
    "    out2.write(img_final)\n",
    "\n",
    "    key = cv2.waitKey(2) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "out2.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBJECT TRACKING WITH BACKGROUND DIFFERENCE + KALMAN FILTER - OCCLUDED VIDEO- NOT WORKING\n",
    "\n",
    "num_imgs = len(frames_oc)\n",
    "\n",
    "fgbg=cv2.createBackgroundSubtractorMOG2()\n",
    "#fgbg=cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "\n",
    "for i in range(0,num_imgs-1):\n",
    "\n",
    "    img= frames_crop_oc[i]\n",
    "    img_final = frames_oc[i]\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask= fgbg.apply(gray)\n",
    "\n",
    "    mask_morph = cv2.morphologyEx(mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "    mask_morph = cv2.morphologyEx(mask_morph, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))) # OR (5,5)\n",
    "\n",
    "    #generate output\n",
    "    output=cv2.bitwise_and(gray,gray, None, mask_morph)\n",
    "\n",
    "\n",
    "    contours, _ = cv2.findContours(output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #maybe change mask to output\n",
    "\n",
    "    for contour in contours:\n",
    "        \n",
    "        (x,y,w,h)= cv2.boundingRect(contour) # from here we will determine the area of the rectangle that surrounds the objects, and if the area of other moving objects is smaller than this one, it will omit them\n",
    " \n",
    "        if cv2.contourArea(contour)< 1500:\n",
    "           continue # we do nothing\n",
    "\n",
    "       \n",
    "        cx = int((x+x+w)/2) #centre coordinates of the object (x+x+w?)\n",
    "        cy = int((y+y+h)/2)\n",
    "        predicted= kf.predict(cx+330,cy)\n",
    "        cv2.circle(img_final, (predicted[0], predicted[1]), 20, (255,0,0), 2) # the circle is the predicted center position of the object\n",
    "\n",
    "\n",
    "    cv2.imshow('video', img_final)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBJECT TRACKING WITH BACKGROUND DIFFERENCE + KALMAN FILTER - OCCLUDED VIDEO - NOT WORKING\n",
    "\n",
    "num_imgs = len(frames_oc)\n",
    "\n",
    "fgbg=cv2.createBackgroundSubtractorMOG2()\n",
    "#fgbg=cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "counter=0\n",
    "\n",
    "for i in range(0,num_imgs-1):\n",
    "\n",
    "    img_kalman = frames_crop_non[i]\n",
    "    img_tracking = frames_crop_oc[i]\n",
    "    img_final = frames_oc[i]\n",
    "\n",
    "\n",
    "    #kalman prediction\n",
    "    gray_kalman = cv2.cvtColor(img_kalman, cv2.COLOR_BGR2GRAY)\n",
    "    mask_kalman= fgbg.apply(gray_kalman)\n",
    "    mask_morph_kalman = cv2.morphologyEx(mask_kalman, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "    mask_morph_kalman = cv2.morphologyEx(mask_morph_kalman, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))) # OR (5,5)\n",
    "\n",
    "    #object tracking\n",
    "\n",
    "    gray = cv2.cvtColor(img_tracking, cv2.COLOR_BGR2GRAY)\n",
    "    mask= fgbg.apply(gray)\n",
    "    mask_morph = cv2.morphologyEx(mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "    mask_morph = cv2.morphologyEx(mask_morph, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "\n",
    "\n",
    "    #generate output\n",
    "    output_kalman=cv2.bitwise_and(gray_kalman,gray_kalman, None, mask_morph_kalman)\n",
    "    output=cv2.bitwise_and(gray,gray, None, mask_morph)\n",
    "\n",
    "    # detect contours\n",
    "    contours_kalman, _ = cv2.findContours(output_kalman, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #maybe change mask to output\n",
    "    contours, _ = cv2.findContours(output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #maybe change mask to output\n",
    "\n",
    "\n",
    "    for contourk, contour in zip(contours_kalman, contours):\n",
    "        \n",
    "        (xk,yk,wk,hk)= cv2.boundingRect(contourk)\n",
    "        (x,y,w,h)= cv2.boundingRect(contour)\n",
    "\n",
    "        if cv2.contourArea(contourk)<1500 and cv2.contourArea(contour)<1500:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        \n",
    "        cv2.rectangle(img_final, (x+330,y), (x+w+330, y+h), (0,255,0), 2)\n",
    "        cx = int((xk+xk+wk)/2) #centre coordinates of the object (x+x+w?)\n",
    "        cy = int((yk+yk+hk)/2)\n",
    "        predicted= kf.predict(cx+330,cy)\n",
    "        cv2.circle(img_final, (predicted[0], predicted[1]), 20, (255,0,0), 2) # the circle is the predicted center position of the object\n",
    "\n",
    "    cv2.imshow(\"video occluded\", img_final)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e81a7d408b84629da7280e4b5e5c6ea4c6dfe1c48d5b31641e461ecf54ae697"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
