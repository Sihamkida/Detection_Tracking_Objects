{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from scipy import ndimage\n",
    "import natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Kalman Filter to predict the trajectory\n",
    "\n",
    "# tracks and predics the trajectory of an object, takes a series of measurements overtime and makes a prediction of next measurement\n",
    "\n",
    "class KalmanFilter:\n",
    "    kf = cv2.KalmanFilter(4, 2)\n",
    "    kf.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "    kf.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "\n",
    "\n",
    "    def predict(self, coordX, coordY):\n",
    "        ''' This function estimates the position of the object'''\n",
    "        measured = np.array([[np.float32(coordX)], [np.float32(coordY)]])\n",
    "        self.kf.correct(measured)\n",
    "        predicted = self.kf.predict()\n",
    "        x, y = int(predicted[0]), int(predicted[1])\n",
    "        return x, y\n",
    "\n",
    "# Initialization of kalman filter\n",
    "kf = KalmanFilter() #When we give it values, it will return the prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-occluded video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_non = sorted(glob.glob(\"../Calibration/videos_rectified/not_occluded/left/*.png\"), key= os.path.getmtime) #to get the images in the right order\n",
    "\n",
    "#video_frames_non = sorted(glob.glob(\"../Images/results/not occluded/*.png\"), key= os.path.getmtime) #to get the images in the right order\n",
    "'''\n",
    "folder = \"../Images/results/not occluded/\"\n",
    "\n",
    "for filename in natsort.natsorted(os.listdir(folder)):\n",
    "    video_frames_non=cv2.imread(os.path.join(folder,filename))\n",
    "'''\n",
    "\n",
    "frames_non = [] # frames read without cropping\n",
    "\n",
    "for frames in video_frames_non:\n",
    "    frames_non.append(cv2.imread(frames))\n",
    "\n",
    "#and crop the  non-occluded ones\n",
    "\n",
    "frames_crop_non=[] #frames read with cropping\n",
    "\n",
    "for imgs in frames_non:\n",
    "    crop_img= imgs[1:700, 330:1150]\n",
    "    frames_crop_non.append(crop_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBJECT TRACKING WITH BACKGROUND DIFFERENCE + KALMAN FILTER - NON-OCCLUDED VIDEO\n",
    "\n",
    "num_imgs = len(frames_non)\n",
    "\n",
    "fgbg=cv2.createBackgroundSubtractorMOG2()\n",
    "#fgbg=cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "\n",
    "for i in range(0,num_imgs-1):\n",
    "\n",
    "\n",
    "    img= frames_crop_non[i]\n",
    "    img_final = frames_non[i]\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask= fgbg.apply(gray)\n",
    "\n",
    "    mask_morph = cv2.morphologyEx(mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "    mask_morph = cv2.morphologyEx(mask_morph, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))) # OR (5,5)\n",
    "\n",
    "    #generate output\n",
    "    output=cv2.bitwise_and(gray,gray, None, mask_morph)\n",
    "\n",
    "\n",
    "    contours, _ = cv2.findContours(output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #maybe change mask to output\n",
    "\n",
    "    for contour in contours:\n",
    "        (x,y,w,h)= cv2.boundingRect(contour) # from here we will determine the area of the rectangle that surrounds the objects, and if the area of other moving objects is smaller than this one, it will omit them\n",
    " \n",
    "        if cv2.contourArea(contour)< 1500:\n",
    "           continue # we do nothing\n",
    "\n",
    "        cv2.rectangle(img_final, (x+330,y), (x+w+330, y+h), (0,255,0), 2)\n",
    "        cx = int((x+x+w)/2) #centre coordinates of the object (x+x+w?)\n",
    "        cy = int((y+y+h)/2)\n",
    "        predicted= kf.predict(cx+330,cy)\n",
    "        cv2.circle(img_final, (predicted[0], predicted[1]), 20, (255,0,0), 2) # the circle is the predicted center position of the object\n",
    "        \n",
    "\n",
    "    cv2.imshow('video', img_final)\n",
    "\n",
    "    #cv2.waitKey(1)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    #key= cv2.waitKey(10)\n",
    "    #if key ==27:\n",
    "    #    break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occluded video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_oc = sorted(glob.glob(\"../Calibration/videos_rectified/occluded/left/*.png\"), key= os.path.getmtime) #to get the images in the right orde\n",
    "\n",
    "frames_oc = [] # frames read without cropping\n",
    "\n",
    "for frames in video_frames_oc:\n",
    "    frames_oc.append(cv2.imread(frames))\n",
    "\n",
    "#and crop the  non-occluded ones\n",
    "\n",
    "frames_crop_oc=[] #frames read with cropping\n",
    "\n",
    "for imgs in frames_oc:\n",
    "    crop_img= imgs[1:700, 330:1150]\n",
    "    frames_crop_oc.append(crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#if motion not found do only predict\\n        X, P = predictKalman(X, P, F, u)\\n        \\n        #drawing the prediction\\n        point_2D, _ = cv2.projectPoints(np.array([[H.dot(X)[0][0], (H.dot(X))[1][0], (H.dot(X))[2][0]]]), np.zeros(3), np.array([0., 0., 0.]), mtx_left,  np.array([0., 0., 0., 0.]))\\n        \\n        cv2.circle(pic, (int(point_2D[0][0][0]), int(point_2D[0][0][1])), 5, (255, 0, 0), -1)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# INITIALIZATIONS (SOME OF THEM MIGHT NOT BE NEEDED IN THE END)\n",
    "\n",
    "\n",
    "cameraMatrixL = np.array([ [699.99033698,   0,         647.56623587],\n",
    "                            [0,         700.19344877, 372.87689895],  \n",
    "                            [  0,           0,          1.        ] ])\n",
    "\n",
    "\n",
    "\n",
    "def predictKalman(x, P, F, u):\n",
    "    X_next = (np.dot(F,x))+u\n",
    "    P_next = np.linalg.multi_dot([F, P, np.transpose(F)])\n",
    "    return X_next, P_next\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def initializeKalman():\n",
    "    ### Initialize Kalman filter ###\n",
    "    # The initial state (6x1).\n",
    "    X = np.array([[1070],  #x position\n",
    "                  [0],      #x velocity\n",
    "                  [357], #y position\n",
    "                  [0],      #y velocity\n",
    "                  [0], #z position\n",
    "                  [0]])     #z velocity\n",
    "    \n",
    "    # The initial uncertainty (6x6).\n",
    "    P = np.identity(6)*10\n",
    "    \n",
    "    # The external motion (6x1).\n",
    "    u = np.zeros((6, 1))\n",
    "    \n",
    "    # The transition matrix (6x6). \n",
    "    F = np.array([[1, 1, 0, 0, 0, 0],\n",
    "                  [0, 1, 0, 0, 0, 0],\n",
    "                  [0, 0, 1, 1, 0, 0],\n",
    "                  [0, 0, 0, 1, 0, 0],\n",
    "                  [0, 0, 0, 0, 1, 1],\n",
    "                  [0, 0, 0, 0, 0, 1]])\n",
    "    \n",
    "    # The observation matrix (3x6).\n",
    "    H = np.array([[1, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 1, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 1, 0]])\n",
    "    \n",
    "    # The measurement uncertainty.\n",
    "    R = 1\n",
    "    \n",
    "    I = np.identity(6)\n",
    "    \n",
    "    return X, P, u, F, H, R, I\n",
    "\n",
    "def re_round(li):\n",
    "     try:\n",
    "         return round(li)\n",
    "     except TypeError:\n",
    "         return type(li)(re_round(x) for x in li)\n",
    "\n",
    "def split(start, end, segments):\n",
    "\n",
    "    dx= round((abs(end[0]-start[0])/float(segments)))\n",
    "    #dy = round((end[1]-start[1]/float(segments)))\n",
    "\n",
    "    dy = round((end[1]-start[1])/segments)\n",
    "    \n",
    "    points= []\n",
    "\n",
    "    for i in range(1, segments):\n",
    "        points.append([start[0]- i*dx, start[1] + i*dy])\n",
    "    \n",
    "    points= [start] + points + [end]\n",
    "    tuples= []\n",
    "   \n",
    "    for point in points:\n",
    "        new= tuple(point)\n",
    "        tuples.append(new)\n",
    "\n",
    "    final = re_round(tuples)\n",
    "    \n",
    "    return final\n",
    "\n",
    "'''\n",
    "\n",
    "#if motion not found do only predict\n",
    "        X, P = predictKalman(X, P, F, u)\n",
    "        \n",
    "        #drawing the prediction\n",
    "        point_2D, _ = cv2.projectPoints(np.array([[H.dot(X)[0][0], (H.dot(X))[1][0], (H.dot(X))[2][0]]]), np.zeros(3), np.array([0., 0., 0.]), cameraMatrixL,  np.array([0., 0., 0., 0.]))\n",
    "        \n",
    "        cv2.circle(pic, (int(point_2D[0][0][0]), int(point_2D[0][0][1])), 5, (255, 0, 0), -1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBJECT TRACKING WITH BACKGROUND DIFFERENCE + KALMAN FILTER - OCCLUDED VIDEO - TRY1\n",
    "\n",
    "num_imgs= len(frames_oc)\n",
    "\n",
    "start=(1070, 357)\n",
    "end = (710,476)\n",
    "\n",
    "fgbg=cv2.createBackgroundSubtractorMOG2()\n",
    "#fgbg=cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "for i in range(0,num_imgs-1):\n",
    "\n",
    "    img= frames_crop_oc[i]\n",
    "    img_final = frames_oc[i]\n",
    "\n",
    "    points= split(start, end, 58)\n",
    "\n",
    "    if i>150 and i<208:\n",
    "        for j in range(0, len(points)-1):\n",
    "            cv2.circle(img_final[i], points[j] ,20, (255,0,0),2)\n",
    "        \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask= fgbg.apply(gray)\n",
    "\n",
    "    mask_morph = cv2.morphologyEx(mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "    mask_morph = cv2.morphologyEx(mask_morph, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))) # OR (5,5)\n",
    "\n",
    "    #generate output\n",
    "    output=cv2.bitwise_and(gray,gray, None, mask_morph)\n",
    "\n",
    "    \n",
    "    contours, _ = cv2.findContours(output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #maybe change mask to output\n",
    "\n",
    "    for contour in contours:\n",
    "        (x,y,w,h)= cv2.boundingRect(contour) # from here we will determine the area of the rectangle that surrounds the objects, and if the area of other moving objects is smaller than this one, it will omit them\n",
    " \n",
    "        if cv2.contourArea(contour)< 1500 and cv2.contourArea(contour)>1:\n",
    "            continue\n",
    "\n",
    "        cv2.rectangle(img_final, (x+330,y), (x+w+330, y+h), (0,255,0), 2)\n",
    "        cx = int((x+x+w)/2) #centre coordinates of the object (x+x+w?)\n",
    "        cy = int((y+y+h)/2)\n",
    "        predicted= kf.predict(cx+330,cy)\n",
    "        cv2.circle(img_final, (predicted[0], predicted[1]), 20, (255,0,0), 2) # the circle is the predicted center position of the object      \n",
    "\n",
    "\n",
    "    cv2.imshow('video', img_final)\n",
    "\n",
    "    #cv2.waitKey(1)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBJECT TRACKING WITH BACKGROUND DIFFERENCE + KALMAN FILTER - OCCLUDED VIDEO - TRY2\n",
    "\n",
    "num_imgs= len(frames_oc)\n",
    "\n",
    "KF= initializeKalman()\n",
    "\n",
    "start=(1070, 357)\n",
    "end = (710,476)\n",
    "\n",
    "fgbg=cv2.createBackgroundSubtractorMOG2()\n",
    "#fgbg=cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "for i in range(0,num_imgs-1):\n",
    "\n",
    "    img= frames_crop_oc[i]\n",
    "    img_final = frames_oc[i]\n",
    "    \n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask= fgbg.apply(gray)\n",
    "\n",
    "    mask_morph = cv2.morphologyEx(mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "    mask_morph = cv2.morphologyEx(mask_morph, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))) # OR (5,5)\n",
    "\n",
    "    #generate output\n",
    "    output=cv2.bitwise_and(gray,gray, None, mask_morph)\n",
    "\n",
    "    if i>150 and i<208:\n",
    "        for j in range(150,208):\n",
    "            img_past= frames_crop_non[j]\n",
    "            gray1 = cv2.cvtColor(img_past, cv2.COLOR_BGR2GRAY)\n",
    "            mask1= fgbg.apply(gray1)\n",
    "\n",
    "            mask_morph1 = cv2.morphologyEx(mask1, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "            mask_morph1 = cv2.morphologyEx(mask_morph1, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))) # OR (5,5)\n",
    "\n",
    "            #generate output\n",
    "            output1=cv2.bitwise_and(gray1,gray1, None, mask_morph)\n",
    "            contours1, _ = cv2.findContours(output1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #maybe change mask to output\n",
    "            for contour1 in contours1:\n",
    "                (x1,y1,w1,h1)= cv2.boundingRect(contour1) # from here we will determine the area of the rectangle that surrounds the objects, and if the area of other moving objects is smaller than this one, it will omit them\n",
    "                if cv2.contourArea(contour1)< 1500:\n",
    "                    continue # we do nothing\n",
    "                cx1 = int((x1+x1+w1)/2) #centre coordinates of the object (x+x+w?)\n",
    "                cy1 = int((y1+y1+h1)/2)\n",
    "                predicted1= kf.predict(cx1+330,cy1)\n",
    "                cv2.circle(img_final, (predicted1[0], predicted1[1]), 20, (255,0,0), 2) # the circle is the predicted center position of the object\n",
    "\n",
    "\n",
    "            #cv2.imshow('video', img_final)\n",
    "\n",
    "    '''\n",
    "        points1= split(start,end,58)\n",
    "        for point in points1:\n",
    "            (x,y)= point\n",
    "            predicted= kf.predict(x,y)\n",
    "            cv2.circle(img_final, (predicted[0],predicted[1]), 20, (255, 0,0), 2)\n",
    "    \n",
    "    if i>351 and i<414:\n",
    "        points2= split(start,end,63)\n",
    "        for point in points2:\n",
    "            cv2.circle(img_final, point,20, (255,0,0),2)\n",
    "\n",
    "    if i>607 and i<665:\n",
    "        points3= split(start,end,58)\n",
    "        for point in points3:\n",
    "            cv2.circle(img_final, point,20, (255,0,0),2)\n",
    "\n",
    "    if i>806 and i<882:\n",
    "        points4= split(start,end,76)\n",
    "        for point in points4:\n",
    "            cv2.circle(img_final, point,20, (255,0,0),2)\n",
    "\n",
    "    if i>1018 and i<1085:\n",
    "        points5= split(start,end,67)\n",
    "        for point in points5:\n",
    "            cv2.circle(img_final, point,20, (255,0,0),2)\n",
    "\n",
    "    if i>1247 and i<1286:\n",
    "        points6= split(start,end,39)\n",
    "        for point in points6:\n",
    "            cv2.circle(img_final, point,20, (255,0,0),2)\n",
    "    '''\n",
    "\n",
    "    \n",
    "    contours, _ = cv2.findContours(output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #maybe change mask to output\n",
    "\n",
    "    for contour in contours:\n",
    "        (x,y,w,h)= cv2.boundingRect(contour) # from here we will determine the area of the rectangle that surrounds the objects, and if the area of other moving objects is smaller than this one, it will omit them\n",
    " \n",
    "        if cv2.contourArea(contour)< 1500 and cv2.contourArea(contour)>1:\n",
    "            continue\n",
    "\n",
    "        cv2.rectangle(img_final, (x+330,y), (x+w+330, y+h), (0,255,0), 2)\n",
    "        cx = int((x+x+w)/2) #centre coordinates of the object (x+x+w?)\n",
    "        cy = int((y+y+h)/2)\n",
    "        predicted= kf.predict(cx+330,cy)\n",
    "        cv2.circle(img_final, (predicted[0], predicted[1]), 20, (255,0,0), 2) # the circle is the predicted center position of the object      \n",
    "\n",
    "    #X,P,u,F,H,R,I = initializeKalman()\n",
    "\n",
    "    # if 150<i<208 or 351<i<414 or 607<i<665 or 806<i<882 or 1018<i<1085 or 1247<i<1286:\n",
    "        \n",
    "        #X,P = predictKalman(X,P,F,u)\n",
    "            #drawing prediction\n",
    "        #point_2D, _ = cv2.projectPoints(np.array([[H.dot(X)[0][0], (H.dot(X))[1][0], (H.dot(X))[2][0]]]), np.zeros(3), np.array([0., 0., 0.]), cameraMatrixL,  np.array([0., 0., 0., 0.]))\n",
    "        \n",
    "        #cv2.circle(img_final, (int(point_2D[0][0][0]), int(point_2D[0][0][1])), 20, (0, 255, 0), 2)\n",
    "        #cv2.circle(img_final, (900,357), 20, (0, 255, 0), 2)\n",
    "        #cv2.line(img_final, (1070, 360), (710,476), (0,255,0), 2)\n",
    "    \n",
    "    \n",
    "\n",
    "    cv2.imshow('video', img_final)\n",
    "\n",
    "    #cv2.waitKey(1)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBJECT TRACKING WITH BACKGROUND DIFFERENCE + KALMAN FILTER - OCCLUDED VIDEO - TRY3\n",
    "\n",
    "num_imgs = len(frames_oc)\n",
    "\n",
    "fgbg=cv2.createBackgroundSubtractorMOG2()\n",
    "#fgbg=cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "\n",
    "for i in range(0,num_imgs-1):\n",
    "\n",
    "\n",
    "    img= frames_crop_oc[i]\n",
    "    img_final = frames_oc[i]\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask= fgbg.apply(gray)\n",
    "\n",
    "    mask_morph = cv2.morphologyEx(mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "    mask_morph = cv2.morphologyEx(mask_morph, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))) # OR (5,5)\n",
    "\n",
    "    #generate output\n",
    "    output=cv2.bitwise_and(gray,gray, None, mask_morph)\n",
    "\n",
    "\n",
    "    contours, _ = cv2.findContours(output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #maybe change mask to output\n",
    "\n",
    "    for contour in contours:\n",
    "        (x,y,w,h)= cv2.boundingRect(contour) # from here we will determine the area of the rectangle that surrounds the objects, and if the area of other moving objects is smaller than this one, it will omit them\n",
    " \n",
    "        if cv2.contourArea(contour)< 1500:\n",
    "           continue # we do nothing\n",
    "\n",
    "        cv2.rectangle(img_final, (x+330,y), (x+w+330, y+h), (0,255,0), 2)\n",
    "        cx = int((x+x+w)/2) #centre coordinates of the object (x+x+w?)\n",
    "        cy = int((y+y+h)/2)\n",
    "        predicted= kf.predict(cx+330,cy)\n",
    "        cv2.circle(img_final, (predicted[0], predicted[1]), 20, (255,0,0), 2) # the circle is the predicted center position of the object\n",
    "\n",
    "\n",
    "    cv2.imshow('video', img_final)\n",
    "\n",
    "    #cv2.waitKey(1)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBJECT TRACKING WITH BACKGROUND DIFFERENCE + KALMAN FILTER - OCCLUDED VIDEO NOT WORKING\n",
    "\n",
    "num_imgs = len(frames_oc)\n",
    "\n",
    "fgbg=cv2.createBackgroundSubtractorMOG2()\n",
    "#fgbg=cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "counter=0\n",
    "\n",
    "for i in range(0,num_imgs-1):\n",
    "\n",
    "    img_kalman = frames_crop_non[i]\n",
    "    img_tracking = frames_crop_oc[i]\n",
    "    img_final = frames_oc[i]\n",
    "\n",
    "\n",
    "    #kalman prediction\n",
    "    gray_kalman = cv2.cvtColor(img_kalman, cv2.COLOR_BGR2GRAY)\n",
    "    mask_kalman= fgbg.apply(gray_kalman)\n",
    "    mask_morph_kalman = cv2.morphologyEx(mask_kalman, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "    mask_morph_kalman = cv2.morphologyEx(mask_morph_kalman, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))) # OR (5,5)\n",
    "\n",
    "    #object tracking\n",
    "\n",
    "    gray = cv2.cvtColor(img_tracking, cv2.COLOR_BGR2GRAY)\n",
    "    mask= fgbg.apply(gray)\n",
    "    mask_morph = cv2.morphologyEx(mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "    mask_morph = cv2.morphologyEx(mask_morph, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "\n",
    "\n",
    "    #generate output\n",
    "    output_kalman=cv2.bitwise_and(gray_kalman,gray_kalman, None, mask_morph_kalman)\n",
    "    output=cv2.bitwise_and(gray,gray, None, mask_morph)\n",
    "\n",
    "    # detect contours\n",
    "    contours_kalman, _ = cv2.findContours(output_kalman, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #maybe change mask to output\n",
    "    contours, _ = cv2.findContours(output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #maybe change mask to output\n",
    "\n",
    "\n",
    "    for contourk, contour in zip(contours_kalman, contours):\n",
    "        \n",
    "        (xk,yk,wk,hk)= cv2.boundingRect(contourk)\n",
    "        (x,y,w,h)= cv2.boundingRect(contour)\n",
    "\n",
    "        if cv2.contourArea(contourk)<1500 and cv2.contourArea(contour)<1500:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        \n",
    "        cv2.rectangle(img_final, (x+330,y), (x+w+330, y+h), (0,255,0), 2)\n",
    "        cx = int((xk+xk+wk)/2) #centre coordinates of the object (x+x+w?)\n",
    "        cy = int((yk+yk+hk)/2)\n",
    "        predicted= kf.predict(cx+330,cy)\n",
    "        cv2.circle(img_final, (predicted[0], predicted[1]), 20, (255,0,0), 2) # the circle is the predicted center position of the object\n",
    "\n",
    "    cv2.imshow(\"video occluded\", img_final)\n",
    "\n",
    "\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e81a7d408b84629da7280e4b5e5c6ea4c6dfe1c48d5b31641e461ecf54ae697"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
